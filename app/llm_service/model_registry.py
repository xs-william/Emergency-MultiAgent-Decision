# ==========================================
# Module: Model Registry
# File: app/llm_service/model_registry.py
# ==========================================
# ğŸ§© æ¨¡å—åŠŸèƒ½ï¼š
#   - æ³¨å†Œä¸åŠ¨æ€é€‰æ‹©å¯ç”¨çš„å¤§æ¨¡å‹å®¢æˆ·ç«¯ï¼›
#   - æœªæ¥å¯æ”¯æŒå¤šå‚å•†æ¨¡å‹ï¼ˆOpenAI, Anthropic, Google, etcï¼‰ã€‚
# ==========================================

from typing import Dict, Type
from app.llm_service.base_client import BaseLLMClient
from app.llm_service.openai_client import OpenAIClient

# å…¨å±€æ¨¡å‹æ³¨å†Œè¡¨
MODEL_REGISTRY: Dict[str, Type[BaseLLMClient]] = {
    "gpt-4o": OpenAIClient,
}

def get_llm_client(model_name: str, api_key: str = None, temperature: float = 0.3) -> BaseLLMClient:
    """æ ¹æ®æ¨¡å‹ååŠ¨æ€å®ä¾‹åŒ–å¯¹åº”å®¢æˆ·ç«¯"""
    client_cls = MODEL_REGISTRY.get(model_name)
    if not client_cls:
        raise ValueError(f"Unsupported model: {model_name}")
    return client_cls(api_key=api_key, model_name=model_name, temperature=temperature)
