# ==========================================
# Module: Pipeline Controller
# File: app/pipeline.py
# ==========================================
# ğŸ§© åŠŸèƒ½æ¦‚è¿°ï¼š
#   - ä¸²è”ç³»ç»Ÿä¸»æ‰§è¡Œæµç¨‹ï¼›
#   - è´Ÿè´£æ¨¡å—é—´æ•°æ®ä¼ é€’ä¸æ—¥å¿—ï¼›
#   - æä¾›ç»™å¯è§†åŒ–ç•Œé¢çš„ç»Ÿä¸€è°ƒç”¨å…¥å£ã€‚
# ==========================================

from planner.multimodal_input import parse_multimodal_input
from planner.intent_recognition import recognize_intent


def run_full_pipeline(text, image, audio, api_key=None):
    """
    ç³»ç»Ÿæ‰§è¡Œä¸»æµç¨‹ï¼š
      1ï¸âƒ£ å¤šæ¨¡æ€è¾“å…¥è§£æï¼›
      2ï¸âƒ£ åŸºäº GPT-4o çš„æ„å›¾è¯†åˆ«ï¼›
      3ï¸âƒ£ è¿”å›æ ‡å‡†åŒ–è¾“å‡ºã€‚
    """
    print("ğŸ”¹ Step 1: Parsing multimodal input...")
    multimodal_data = parse_multimodal_input(text, image, audio)

    print("ğŸ”¹ Step 2: Recognizing intent (via GPT-4o)...")
    intent_result = recognize_intent(multimodal_data, api_key=api_key)

    # âš™ï¸ é¢„ç•™åç»­æ¨¡å—
    return {
        "final_summary": intent_result,
        "visual_outputs": []  # aggregator æ¥å£å ä½
    }


if __name__ == "__main__":
    demo = run_full_pipeline(
        text="Fire detected in east building, analyze danger and plan rescue.",
        image="./examples/demo_input/fire_scene.jpg",
        audio=None,
        api_key=None
    )
    print(demo)
